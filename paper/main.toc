\contentsline {section}{\numberline {1}Introduction}{2}{section.1}%
\contentsline {subsection}{\numberline {1.1}Main contributions}{2}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Related work}{3}{subsection.1.2}%
\contentsline {paragraph}{Loss landscape of neural networks.}{3}{section*.2}%
\contentsline {paragraph}{Overparameterization and global convergence.}{3}{section*.3}%
\contentsline {paragraph}{Random matrix theory in ML.}{3}{section*.4}%
\contentsline {section}{\numberline {2}Problem Setup}{4}{section.2}%
\contentsline {subsection}{\numberline {2.1}Network architecture and loss}{4}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Data model}{4}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}The Hessian structure}{5}{subsection.2.3}%
\contentsline {section}{\numberline {3}The Spectral Decoupling}{5}{section.3}%
\contentsline {section}{\numberline {4}Main Results}{7}{section.4}%
\contentsline {subsection}{\numberline {4.1}The critical ratio}{7}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}The phase transition}{8}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Spectral gap scaling}{9}{subsection.4.3}%
\contentsline {section}{\numberline {5}Proofs}{10}{section.5}%
\contentsline {subsection}{\numberline {5.1}Proof of Theorem~\ref {thm:critical-ratio}: Identifying the critical ratio}{10}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Proof of Theorem~\ref {thm:phase-transition}: The phase transition}{12}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Proof of Theorem~\ref {thm:scaling}: Linear spectral gap scaling}{13}{subsection.5.3}%
\contentsline {section}{\numberline {6}The Isotropic Case: Explicit Computations}{14}{section.6}%
\contentsline {section}{\numberline {7}The Second Moment Method and Concentration}{16}{section.7}%
\contentsline {section}{\numberline {8}Extensions and Discussion}{17}{section.8}%
\contentsline {subsection}{\numberline {8.1}Non-isotropic data: the role of the condition number}{17}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Connection to the neural tangent kernel}{17}{subsection.8.2}%
\contentsline {subsection}{\numberline {8.3}Implications for practice}{17}{subsection.8.3}%
\contentsline {subsection}{\numberline {8.4}Empirical validation on real data}{17}{subsection.8.4}%
\contentsline {subsection}{\numberline {8.5}General activation functions}{18}{subsection.8.5}%
\contentsline {subsection}{\numberline {8.6}Universality beyond Gaussian data}{20}{subsection.8.6}%
\contentsline {section}{\numberline {9}Landscape Geometry versus Optimization Dynamics}{21}{section.9}%
\contentsline {subsection}{\numberline {9.1}Empirical observations}{21}{subsection.9.1}%
\contentsline {subsection}{\numberline {9.2}Interpretation}{22}{subsection.9.2}%
\contentsline {section}{\numberline {10}Conclusion}{22}{section.10}%
\contentsline {section}{\numberline {A}Additional Figures}{23}{appendix.A}%
